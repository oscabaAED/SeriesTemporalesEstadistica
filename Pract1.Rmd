---
title: "Proyecto"
author: "Óscar Camacho Barreda"
date: "2025-10-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(forecast)
library(lmtest)
library(ggplot2)

stock <- read.csv("stock_returns_train.csv")

stock 

serie1 <- ts(data = stock$X1, frequency = 12)
plot(serie1)

serie2 <- ts(data = stock$X2, frequency = 12)
plot(serie2)

serie3 <- ts(data = stock$X3, frequency = 12)
plot(serie3)

serie4 <- ts(data = stock$X4, frequency = 12)
plot(serie4)

serie5 <- ts(data = stock$X5, frequency = 12)
plot(serie5)
```

```{r Extracción de ventana}
serie1_train <- ts(serie1[1:(5*12)], frequency = frequency(serie1))
plot(serie1_train)
serie1_test <- ts(serie1[((5*12) + 1):length(serie1)], frequency = frequency(serie1))
```


```{r Eliminación de la estacionalidad, determinación D}
# Primero se calculas diferencias sucesivas
dserie1 <- diff(serie1_train, lag = frequency(serie1))
plot(dserie1)
ddserie1 <- diff(dserie1, lag = frequency(serie1))
plot(ddserie1)
dddserie1 <- diff(ddserie1, lag = frequency(serie1))
plot(dddserie1)
ddddserie1 <- diff(dddserie1, lag = frequency(serie1))
plot(ddddserie1)
```

```{r Eliminación de la tendencia, determinación de la d}
dserie1 <- diff(serie1_train)
plot(dserie1)
ddserie1 <- diff(dserie1)
plot(ddserie1)
dddserie1 <- diff(ddserie1)
plot(dddserie1)
ddddserie1 <- diff(dddserie1)
plot(ddddserie1)
```


Ahora vemos si se cumple la hipótesis de homocedasticidad:

```{r Homocedasticidad}
# Se grafica la serie elevada al cuadrado (al hacer la resta la media se ha ido)
plot(dddserie1^2)

# Contraste de hipótesis Goldfeld-Quandt para la comprobación de la homocedasticidad
library(lmtest)
gqtest( lm(x~.,data=as.data.frame(dddserie1)) )
```
```{r Gráficos de correlación}
acf(serie1_train,lag.max=60)
pacf(serie1_train,lag.max=60)
```

A la vista de las gráficas anteriores estimamos que $p = q = 2$ y $Q = 0$, pero para $P$ no sabemos si se trata de $2$ o $0$. Tenemos entonces dos modelos candidatos.

```{r Estimación de los parámetros}

vec_minus11 <- c(p = 2, d = 0, q = 2)

vec_mayus11 <- c(P = 0, D = 0, Q = 0)
vec_mayus12 <- c(P = 2, D = 0, Q = 0)
```

Creamos dos modelos, con las dos posibles elecciones de parámetros.

```{r Creación de los modelos}

model1 <- arima(serie1_train, order=vec_minus11, seasonal=list(order=vec_mayus11, period=frequency(serie1_train)))


model2 <- arima(serie1_train, order=vec_minus11, seasonal=list(order=vec_mayus12, period=frequency(serie1_train)))
```

Pero hay una función interna que nos estimas los mejores valores óptimos de los parámetros del modelo. Entonces, vamos a comparar el resultado de esta función llamada `auto.arima`.

```{r Estimación con auto.arima}
Modelo_auto <- auto.arima(serie1_train, d=0, D=0, max.p = 2, max.q = 2, max.P = 2, max.Q = 2)
Modelo_auto
```

El método estima que los parámetros son nulos todos. Para ver cual es el método que mejor ajusta, usamos la función `accuracy`.

```{r Comparación de modelos}
accuracy(Modelo_auto)
accuracy(model1)
accuracy(model2)
```
**Los modelos propuestos son mejores que el dado por la función `auto.arima`.**

```{r Comparación de la estimación}
fitval <- model2$residuals # Valores ajustados

plot(serie1_train,ylab="Num Pasajeros")
lines(fitval,col="red")
```

El modelo hace una predicción aceptable.

```{r}
plot(forecast(model1, h=36))
lines(serie1, col = "red")
lines(model1$residuals, col="blue")
```

```{r}
plot(forecast(model2, h=36))
lines(serie1, col = "red")
lines(model2$residuals, col="blue")
```
